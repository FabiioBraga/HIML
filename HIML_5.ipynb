{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c997af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from os import getcwd\n",
    "from os.path import join \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.multivariate.pca import PCA\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17aa7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = join(os.getcwd(),'data','data3SS2009.mat')\n",
    "\n",
    "mat_contents = sio.loadmat(fname)\n",
    "\n",
    "dataset = mat_contents['dataset']\n",
    "\n",
    "\n",
    "N, Chno, Nc = dataset.shape\n",
    "# N: number of samples\n",
    "# Chno: number of channels\n",
    "# Nc: number of cases\n",
    "\n",
    "y = mat_contents['labels'].reshape(Nc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e1d4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch1 = dataset[:,0,:] # célula de carga: força do shaker\n",
    "Ch2 = dataset[:,1,:] # acelerômetro: base\n",
    "Ch3 = dataset[:,2,:] # acelerômetro: 1o andar\n",
    "Ch4 = dataset[:,3,:] # acelerômetro: 2o andar\n",
    "Ch5 = dataset[:,4,:] # acelerômetro: 3o andar\n",
    "\n",
    "Ts = 3.125 * 1e-3 # sampling time\n",
    "time = (np.linspace(1,N,N) - 1) * Ts\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cea26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARmodel_2 = AutoReg(Ch2[:,1],30,old_names=False).fit()\n",
    "ARmodel_3 = AutoReg(Ch3[:,1],30,old_names=False).fit()\n",
    "ARmodel_4 = AutoReg(Ch4[:,1],30,old_names=False).fit()\n",
    "ARmodel_5 = AutoReg(Ch5[:,1],30,old_names=False).fit()\n",
    "vec_2 = ARmodel_2.params\n",
    "vec_3 = ARmodel_3.params\n",
    "vec_4 = ARmodel_4.params\n",
    "vec_5 = ARmodel_5.params\n",
    "vec_temp = np.concatenate((vec_2,vec_3,vec_4,vec_5))\n",
    "\n",
    "ARmodel_var = vec_temp\n",
    "\n",
    "for i in range(1,850):\n",
    "    ARmodel_2 = AutoReg(Ch2[:,i],30,old_names=False).fit()\n",
    "    ARmodel_3 = AutoReg(Ch3[:,i],30,old_names=False).fit()\n",
    "    ARmodel_4 = AutoReg(Ch4[:,i],30,old_names=False).fit()\n",
    "    ARmodel_5 = AutoReg(Ch5[:,i],30,old_names=False).fit()\n",
    "    vec_2 = ARmodel_2.params\n",
    "    vec_3 = ARmodel_3.params\n",
    "    vec_4 = ARmodel_4.params\n",
    "    vec_5 = ARmodel_5.params\n",
    "    vec_temp = np.concatenate((vec_2,vec_3,vec_4,vec_5))\n",
    "    ARmodel_var = np.vstack([ARmodel_var,vec_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ARmodel_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import mode\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (train_test_split, RepeatedKFold,\n",
    "RandomizedSearchCV)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "927972a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LRG: {}\n",
      "Best Score for LRG: 0.07759605785618238\n",
      "Best Hyperparameters for SVR: {'C': 2.948404943774676, 'epsilon': 0.0468869473545328}\n",
      "Best Score for SVR: 0.046721744857742276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "810 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 381, in fit\n",
      "    splitter = SPLITTERS[self.splitter](\n",
      "KeyError: 'freedom'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.066              nan -0.067              nan         nan         nan\n",
      "         nan         nan -0.06533333         nan -0.067              nan\n",
      " -0.068      -0.04779688 -0.06550803         nan         nan         nan\n",
      "         nan         nan -0.065      -0.067              nan         nan\n",
      "         nan         nan         nan         nan         nan -0.06733333\n",
      " -0.06866667 -0.06569546         nan -0.06566667 -0.06433333 -0.06570936\n",
      "         nan -0.06966667 -0.06520009 -0.04998069 -0.06766667         nan\n",
      "         nan -0.04669461 -0.05537446         nan -0.04851783 -0.05845779\n",
      " -0.04782763 -0.068      -0.06531564         nan -0.06575292         nan\n",
      " -0.0637464  -0.06433333         nan         nan         nan         nan\n",
      "         nan         nan -0.04998069 -0.06666667         nan         nan\n",
      " -0.04998069         nan         nan         nan         nan -0.04669461\n",
      " -0.05706653 -0.06766667         nan         nan -0.04998069 -0.04669461\n",
      "         nan -0.05381625 -0.067              nan         nan         nan\n",
      "         nan         nan         nan -0.05412907 -0.04799362         nan\n",
      "         nan         nan -0.04998069 -0.06666667 -0.06466667         nan\n",
      "         nan         nan -0.05859454 -0.06262747]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for DTR: {'criterion': 'friedman_mse', 'max_depth': 3, 'splitter': 'best'}\n",
      "Best Score for DTR: 0.046694611889162775\n",
      "Best Hyperparameters for KNN: {'n_neighbors': 22, 'p': 2, 'weights': 'distance'}\n",
      "Best Score for KNN: 0.044905119508557315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxcas\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for RFR: {'criterion': 'mse', 'max_depth': 5, 'max_features': 0.942853570557981, 'n_estimators': 72}\n",
      "Best Score for RFR: 0.03846553120132713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models = {\n",
    "    \"LRG\": LinearRegression(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"DTR\": DecisionTreeRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"RFR\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "param_dists = {\n",
    "    \"LRG\": {},\n",
    "    \"SVR\": {\n",
    "        'C': uniform(0.1, 10.0),\n",
    "        'epsilon': uniform(0.01, 1.0)\n",
    "    },\n",
    "     \"DTR\": {\n",
    "        'criterion': ['mse', 'friedman_mse',],\n",
    "        'max_depth': randint(2, 20),\n",
    "         'splitter' : [\"best\",\"freedom\"]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': randint(1, 30),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    \"RFR\": {\n",
    "         'n_estimators': randint(2, 100),\n",
    "        'max_depth': randint(2, 20),\n",
    "        'criterion': ['mse', 'mae',],\n",
    "        'max_features' : stats.uniform()\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# Perform Randomized Search for each model\n",
    "for model_name, model in models.items():\n",
    "    param_dist = param_dists[model_name]\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=100,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    \n",
    "     random_search.fit(X, y)  \n",
    "\n",
    "    \n",
    "    print(f\"Best Hyperparameters for {model_name}:\", random_search.best_params_)\n",
    "    print(f\"Best Score for {model_name}:\", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f136f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
